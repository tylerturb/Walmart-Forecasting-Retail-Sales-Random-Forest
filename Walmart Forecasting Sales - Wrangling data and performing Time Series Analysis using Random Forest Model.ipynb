{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset - Kaggle.com/WalmartM5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The M5 dataset, generously made available by Walmart, involves the unit sales of various products sold in the USA, organized in the form of grouped time series. More specifically, the dataset involves the unit sales of 3,049 products, classified in 3 product categories (Hobbies, Foods, and Household) and 7 product departments, in which the above-mentioned categories are disaggregated.  The products are sold across ten stores, located in three States (CA, TX, and WI). In this respect, the bottom-level of the hierarchy, i.e., product-store unit sales can be mapped across either product categories or geographical regions, as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1: Number of M5 series per aggregation level.\n",
    " Level \n",
    "id\tAggregation Level\tNumber of series\n",
    "1\tUnit sales of all products, aggregated for all stores/states\t1\n",
    "2\tUnit sales of all products, aggregated for each State\t3\n",
    "3\tUnit sales of all products, aggregated for each store \t10\n",
    "4\tUnit sales of all products, aggregated for each category\t3\n",
    "5\tUnit sales of all products, aggregated for each department\t7\n",
    "6\tUnit sales of all products, aggregated for each State and category\t9\n",
    "7\tUnit sales of all products, aggregated for each State and department\t21\n",
    "8\tUnit sales of all products, aggregated for each store and category\t30\n",
    "9\tUnit sales of all products, aggregated for each store and department\t70\n",
    "10\tUnit sales of product x, aggregated for all stores/states\t3,049\n",
    "11\tUnit sales of product x, aggregated for each State\t9,147\n",
    "12\tUnit sales of product x, aggregated for each store\t30,490\n",
    "Total\t42,840 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import regex as re\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These helper and data cleaning functions are from the fast.ai course\n",
    "# The repository is here: https://github.com/fastai/fastai/tree/master\n",
    "\n",
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n",
    "        display(df)\n",
    "        \n",
    "def make_date(df, date_field:str):\n",
    "    \"Make sure `df[field_name]` is of the right date type.\"\n",
    "    field_dtype = df[date_field].dtype\n",
    "    if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "        field_dtype = np.datetime64\n",
    "    if not np.issubdtype(field_dtype, np.datetime64):\n",
    "        df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True)\n",
    "        \n",
    "\n",
    "def add_datepart(df, fldnames, drop=True, time=False, errors=\"raise\"):\n",
    "    # add_datepart converts a column of df from a datetime64 to many columns containing the information from the date. \n",
    "    # This applies changes inplace.\n",
    "    if isinstance(fldnames,str): \n",
    "        fldnames = [fldnames]\n",
    "    for fldname in fldnames:\n",
    "        fld = df[fldname]\n",
    "        fld_dtype = fld.dtype\n",
    "        if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "            fld_dtype = np.datetime64\n",
    "\n",
    "        if not np.issubdtype(fld_dtype, np.datetime64):\n",
    "            df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True, errors=errors)\n",
    "        targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "        attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
    "                'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "        if time: attr = attr + ['Hour', 'Minute', 'Second']\n",
    "        for n in attr: df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
    "        df[targ_pre + 'Elapsed'] = fld.astype(np.int64) // 10 ** 9\n",
    "        if drop: df.drop(fldname, axis=1, inplace=True)\n",
    "        \n",
    "        \n",
    "def ifnone (a,b): #(a:Any,b:Any)->Any:\n",
    "    \"`a` if `a` is not None, otherwise `b`.\"\n",
    "    return b if a is None else a\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=10, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)\n",
    "\n",
    "\n",
    "def train_cats(df):    \n",
    "    for n,c in df.items():\n",
    "        if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()\n",
    "\n",
    "def apply_cats(df, trn):\n",
    "    for n,c in df.items():\n",
    "        if (n in trn.columns) and (trn[n].dtype.name=='category'):\n",
    "            df[n] = c.astype('category').cat.as_ordered()\n",
    "            df[n].cat.set_categories(trn[n].cat.categories, ordered=True, inplace=True)\n",
    "\n",
    "def numericalize(df, col, name, max_n_cat):\n",
    "    if not is_numeric_dtype(col) and ( max_n_cat is None or len(col.cat.categories)>max_n_cat):\n",
    "        df[name] = pd.Categorical(col).codes+1\n",
    "\n",
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)      \n",
    "\n",
    "\n",
    "# End fast.ai funcitons\n",
    "\n",
    "\n",
    "# This reduce memory function came from: https://www.kaggle.com/siavrez\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    #return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal = pd.read_csv('calendar.csv', parse_dates= ['date'])\n",
    "df_sales_train = pd.read_csv('sales_train_validation.csv')\n",
    "df_prices = pd.read_csv('sell_prices.csv')\n",
    "df_submissions = pd.read_csv('sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1969, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30490, 1919), (6841121, 4), (60980, 29))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales_train.shape, df_prices.shape, df_submissions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  d_1907  d_1908  \\\n",
       "0       CA    0    0    0    0  ...       1       3       0       1       1   \n",
       "1       CA    0    0    0    0  ...       0       0       0       0       0   \n",
       "2       CA    0    0    0    0  ...       2       1       2       1       1   \n",
       "3       CA    0    0    0    0  ...       1       0       5       4       1   \n",
       "4       CA    0    0    0    0  ...       2       1       1       0       1   \n",
       "\n",
       "   d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "0       1       3       0       1       1  \n",
       "1       1       0       0       0       0  \n",
       "2       1       0       1       1       1  \n",
       "3       0       1       3       7       2  \n",
       "4       1       2       2       2       4  \n",
       "\n",
       "[5 rows x 1919 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sales_train data provided\n",
    "df_sales_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  F1  F2  F3  F4  F5  F6  F7  F8  F9  ...  \\\n",
       "0  HOBBIES_1_001_CA_1_validation   0   0   0   0   0   0   0   0   0  ...   \n",
       "1  HOBBIES_1_002_CA_1_validation   0   0   0   0   0   0   0   0   0  ...   \n",
       "2  HOBBIES_1_003_CA_1_validation   0   0   0   0   0   0   0   0   0  ...   \n",
       "3  HOBBIES_1_004_CA_1_validation   0   0   0   0   0   0   0   0   0  ...   \n",
       "4  HOBBIES_1_005_CA_1_validation   0   0   0   0   0   0   0   0   0  ...   \n",
       "\n",
       "   F19  F20  F21  F22  F23  F24  F25  F26  F27  F28  \n",
       "0    0    0    0    0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submission format\n",
    "df_submissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to adjust the format of the data given to work with prediction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['d_1', 'd_2', 'd_3', 'd_4', 'd_5', 'd_6', 'd_7', 'd_8', 'd_9', 'd_10',\n",
       "       ...\n",
       "       'd_1904', 'd_1905', 'd_1906', 'd_1907', 'd_1908', 'd_1909', 'd_1910',\n",
       "       'd_1911', 'd_1912', 'd_1913'],\n",
       "      dtype='object', length=1913)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All columns which are not days we will put into a list\n",
    "\n",
    "list_id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'] \n",
    "df_d_cols = df_sales_train.drop(list_id_vars, axis=1)\n",
    "#date columns assigned to a new variable \n",
    "df_d_cols.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "# Pandas melt function UNPIVOTS column values and puts them into rows. Row for every day for an item/store combination. \n",
    "# This puts data into a flat format that will allow us to merge the sales train data with valendar and pricing data sets\n",
    "%time df_melted_sales = df_sales_train.melt(id_vars = list_id_vars, value_vars = df_d_cols.columns, var_name = 'd', value_name = 'sales') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id    d  sales  \n",
       "0       CA  d_1      0  \n",
       "1       CA  d_1      0  \n",
       "2       CA  d_1      0  \n",
       "3       CA  d_1      0  \n",
       "4       CA  d_1      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resulting melted sales data\n",
    "df_melted_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id    d  sales\n",
       "0  HOBBIES_1_001_CA_1_validation  d_1      0\n",
       "1  HOBBIES_1_002_CA_1_validation  d_1      0\n",
       "2  HOBBIES_1_003_CA_1_validation  d_1      0\n",
       "3  HOBBIES_1_004_CA_1_validation  d_1      0\n",
       "4  HOBBIES_1_005_CA_1_validation  d_1      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These columns are redundant to ID - drop them.\n",
    "# This notebook keeps running into the 16 GB of RAM given in free Kaggle.\n",
    "# trying to keep the DFs as small as possible.\n",
    "df_melted_sales.drop(['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], axis=1, inplace = True) \n",
    "df_melted_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>F1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>F1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>F1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>F1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>F1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id   d  sales\n",
       "0  HOBBIES_1_001_CA_1_validation  F1      0\n",
       "1  HOBBIES_1_002_CA_1_validation  F1      0\n",
       "2  HOBBIES_1_003_CA_1_validation  F1      0\n",
       "3  HOBBIES_1_004_CA_1_validation  F1      0\n",
       "4  HOBBIES_1_005_CA_1_validation  F1      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_cols = df_submissions.drop(['id'], axis=1).columns\n",
    "\n",
    "# Like what we did to the sales data, we also need to melt the submission \n",
    "df_melted_sub = df_submissions.melt(id_vars = ['id'], value_vars = sub_cols, \n",
    "                                    var_name = 'd', value_name = 'sales') \n",
    "df_melted_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  d  sales\n",
       "0  HOBBIES_1_001_CA_1_validation  1      0\n",
       "1  HOBBIES_1_002_CA_1_validation  1      0\n",
       "2  HOBBIES_1_003_CA_1_validation  1      0\n",
       "3  HOBBIES_1_004_CA_1_validation  1      0\n",
       "4  HOBBIES_1_005_CA_1_validation  1      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_melted_sub['d'] = df_melted_sub['d'].str.replace('F','')\n",
    "df_melted_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>d_1914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>d_1914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>d_1914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>d_1914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>d_1914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id       d sales\n",
       "0  HOBBIES_1_001_CA_1_validation  d_1914     0\n",
       "1  HOBBIES_1_002_CA_1_validation  d_1914     0\n",
       "2  HOBBIES_1_003_CA_1_validation  d_1914     0\n",
       "3  HOBBIES_1_004_CA_1_validation  d_1914     0\n",
       "4  HOBBIES_1_005_CA_1_validation  d_1914     0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_melted_sub['d'] = pd.to_numeric(df_melted_sub['d'], errors='coerce') \n",
    "df_melted_sub['d'] = df_melted_sub['d'] + 1913\n",
    "df_melted_sub = df_melted_sub.applymap(str)\n",
    "df_melted_sub['d'] = 'd_'+ df_melted_sub['d'].astype(str)\n",
    "df_melted_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1707435</th>\n",
       "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707436</th>\n",
       "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707437</th>\n",
       "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707438</th>\n",
       "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707439</th>\n",
       "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id       d sales\n",
       "1707435  FOODS_3_823_WI_3_evaluation  d_1941     0\n",
       "1707436  FOODS_3_824_WI_3_evaluation  d_1941     0\n",
       "1707437  FOODS_3_825_WI_3_evaluation  d_1941     0\n",
       "1707438  FOODS_3_826_WI_3_evaluation  d_1941     0\n",
       "1707439  FOODS_3_827_WI_3_evaluation  d_1941     0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As per the contest notes, this should end at \"d_1941,\" so that's what we should see here...\n",
    "df_melted_sub.tail() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free up some RAM¶\n",
    "The free Kaggle notebook only gives 16GB of RAM. So we'll delete the initial DFs that were merged into larger DFs and run the \"reduce_mem\" function on all DFs that we are going to be using in the next section of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_cal\t df_d_cols\t df_melted_sales\t df_melted_sub\t df_prices\t df_sales_train\t df_submissions\t \n"
     ]
    }
   ],
   "source": [
    "%who DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_sales_train\n",
    "del df_submissions\n",
    "del df_d_cols\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
      "Mem. usage decreased to 1001.26 Mb (25.0% reduction)\n",
      "Mem. usage decreased to 39.08 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "reduce_mem_usage(df_cal)\n",
    "reduce_mem_usage(df_melted_sales)\n",
    "reduce_mem_usage(df_melted_sub) \n",
    "reduce_mem_usage(df_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split \n",
    "I'm using a smaller subet of data because it'll be faster to read and predict and to be able to keep it all in the free Kaggle RAM. Note that because this is a time series problem I'm not using scikit-learn train test split. This is because we want to train with older data and test with new data to simulate actual conditions. You will have all historical data, and will try to predict the next few months... Train test split will randomly split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limited the sample size so we can keep it in RAM in a free Kaggle kernel.\n",
    "# Doing it as an 80/20 split as is standard for train/test.\n",
    "df_test = df_melted_sales.tail(20000) \n",
    "df_train = df_melted_sales.iloc[-120000:-20000] \n",
    "df_submission = df_melted_sub.copy() # Copied just to keep naming conventions consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58307365</th>\n",
       "      <td>HOUSEHOLD_2_243_CA_4_validation</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58307366</th>\n",
       "      <td>HOUSEHOLD_2_244_CA_4_validation</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58307367</th>\n",
       "      <td>HOUSEHOLD_2_245_CA_4_validation</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58307368</th>\n",
       "      <td>HOUSEHOLD_2_246_CA_4_validation</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58307369</th>\n",
       "      <td>HOUSEHOLD_2_247_CA_4_validation</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id       d  sales\n",
       "58307365  HOUSEHOLD_2_243_CA_4_validation  d_1913      0\n",
       "58307366  HOUSEHOLD_2_244_CA_4_validation  d_1913      0\n",
       "58307367  HOUSEHOLD_2_245_CA_4_validation  d_1913      0\n",
       "58307368  HOUSEHOLD_2_246_CA_4_validation  d_1913      0\n",
       "58307369  HOUSEHOLD_2_247_CA_4_validation  d_1913      3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58307370</th>\n",
       "      <td>HOUSEHOLD_2_248_CA_4_validation</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58307371</th>\n",
       "      <td>HOUSEHOLD_2_249_CA_4_validation</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58307372</th>\n",
       "      <td>HOUSEHOLD_2_250_CA_4_validation</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58307373</th>\n",
       "      <td>HOUSEHOLD_2_251_CA_4_validation</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58307374</th>\n",
       "      <td>HOUSEHOLD_2_252_CA_4_validation</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id       d  sales\n",
       "58307370  HOUSEHOLD_2_248_CA_4_validation  d_1913      2\n",
       "58307371  HOUSEHOLD_2_249_CA_4_validation  d_1913      0\n",
       "58307372  HOUSEHOLD_2_250_CA_4_validation  d_1913      0\n",
       "58307373  HOUSEHOLD_2_251_CA_4_validation  d_1913      0\n",
       "58307374  HOUSEHOLD_2_252_CA_4_validation  d_1913      0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If this was done right, the number in the id and d columns below should pick up where it left off above\n",
    "df_test.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 3), (20000, 3), (1707440, 3))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape, df_submission.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge\n",
    "\n",
    "Now we'll combine all the reference data to the training and test data into the training and test data frames.\n",
    "\n",
    "In addition to the standard train/test dfs, we're also going to take the same steps with the submission data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 16), (20000, 16), (1707440, 16))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the calendar data with the training, test and submission DFs\n",
    "df_train = df_train.merge(df_cal, left_on='d', right_on='d', how='left')\n",
    "df_test = df_test.merge(df_cal, left_on='d', right_on='d', how='left')\n",
    "df_submission = df_submission.merge(df_cal, left_on='d', right_on='d', how='left')\n",
    "df_train.shape, df_test.shape, df_submission.shape # should be same numb of cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11325</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>HOBBIES_1_001_CA_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11326</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>HOBBIES_1_001_CA_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11327</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>HOBBIES_1_001_CA_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11328</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>HOBBIES_1_001_CA_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11329</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>HOBBIES_1_001_CA_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wm_yr_wk  sell_price                  id\n",
       "0     11325    9.578125  HOBBIES_1_001_CA_1\n",
       "1     11326    9.578125  HOBBIES_1_001_CA_1\n",
       "2     11327    8.257812  HOBBIES_1_001_CA_1\n",
       "3     11328    8.257812  HOBBIES_1_001_CA_1\n",
       "4     11329    8.257812  HOBBIES_1_001_CA_1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because we dropped columns from the training/test/submit DFs, we have to do this to be able to join to prices.\n",
    "df_prices['id'] = df_prices['item_id'] +'_' + df_prices['store_id']\n",
    "df_prices.drop(['item_id', 'store_id'], axis=1, inplace = True)\n",
    "df_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training and submission data have a suffix that's not in the price data.\n",
    "# So here we're creating a column that matches the price id column.\n",
    "df_train['id_for_price'] = df_train['id'].str.replace('_validation','')\n",
    "df_test['id_for_price'] = df_test['id'].str.replace('_validation','')\n",
    "df_submission['id_for_price'] = df_submission['id'].str.replace('_evaluation','')\n",
    "df_submission['id_for_price'] = df_submission['id_for_price'].str.replace('_validation','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the price data with the training, test and submission DFs\n",
    "df_train = pd.merge(df_train, df_prices,  how='left', left_on=['id_for_price', 'wm_yr_wk'], \n",
    "                    right_on = ['id', 'wm_yr_wk'])\n",
    "df_test = pd.merge(df_test, df_prices,  how='left', left_on=['id_for_price', 'wm_yr_wk'], \n",
    "                   right_on = ['id', 'wm_yr_wk'])\n",
    "df_submission = pd.merge(df_submission, df_prices,  how='left', left_on=['id_for_price', 'wm_yr_wk'], \n",
    "                         right_on = ['id', 'wm_yr_wk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, (100000, 19), 20000, (20000, 19), 1707440, (1707440, 19))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if there are any missing prices\n",
    "df_train['sell_price'].count(), df_train.shape, df_test['sell_price'].count(), df_test.shape, df_submission['sell_price'].count(), df_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging with price added a bunch of unneeded columns\n",
    "df_train.drop(['id_for_price', 'id_y'], axis=1, inplace = True) \n",
    "df_train.rename(columns = {\"id_x\":\"id\"}, inplace = True)\n",
    "df_test.drop(['id_for_price', 'id_y'], axis=1, inplace = True) \n",
    "df_test.rename(columns = {\"id_x\":\"id\"}, inplace = True)\n",
    "df_submission.drop(['id_for_price', 'id_y'], axis=1, inplace = True) \n",
    "df_submission.rename(columns = {\"id_x\":\"id\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_cal\t df_melted_sales\t df_melted_sub\t df_prices\t df_submission\t df_test\t df_train\t \n"
     ]
    }
   ],
   "source": [
    "%who DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To save some RAM we will get rid of the dataframes that we merged from and are not in use now.\n",
    "del df_cal\n",
    "del df_melted_sales\n",
    "del df_melted_sub\n",
    "del df_prices\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  8.11 Mb (0.0% reduction)\n",
      "Mem. usage decreased to  1.60 Mb (1.2% reduction)\n",
      "Mem. usage decreased to 148.18 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "reduce_mem_usage(df_train)\n",
    "reduce_mem_usage(df_test)\n",
    "reduce_mem_usage(df_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the DFs for easy rollback and as a good starting point when reopening the notebook.\n",
    "\n",
    "# Pickles\n",
    "df_train.to_pickle('df_train_pickle.pkl')\n",
    "df_test.to_pickle('df_test_pickle.pkl')\n",
    "df_submission.to_pickle('df_submissions_pickle.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to load the pickle files...\n",
    "df_train = pd.read_pickle('df_train_pickle.pkl')\n",
    "df_test = pd.read_pickle('df_test_pickle.pkl')\n",
    "df_submission = pd.read_pickle('df_submissions_pickle.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to get all the data in the DFs numeric and remove nulls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cols_with_missing = df_merged.columns[df_merged.isnull().any()].tolist()\n",
    "df_train.columns[df_train.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before removing nulls add a boolean column to declare if the value was missing\n",
    "cols_with_missing = df_train.columns[df_train.isnull().any()].tolist()\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    df_train[col + '_was_missing'] = df_train[col].isnull()\n",
    "    df_test[col + '_was_missing'] = df_test[col].isnull()\n",
    "    df_submission[col + '_was_missing'] = df_submission[col].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 21),\n",
       " id                          100000\n",
       " d                           100000\n",
       " sales                       100000\n",
       " date                        100000\n",
       " wm_yr_wk                    100000\n",
       " weekday                     100000\n",
       " wday                        100000\n",
       " month                       100000\n",
       " year                        100000\n",
       " event_name_1                100000\n",
       " event_type_1                100000\n",
       " event_name_2                100000\n",
       " event_type_2                100000\n",
       " snap_CA                     100000\n",
       " snap_TX                     100000\n",
       " snap_WI                     100000\n",
       " sell_price                  100000\n",
       " event_name_1_was_missing    100000\n",
       " event_type_1_was_missing    100000\n",
       " event_name_2_was_missing    100000\n",
       " event_type_2_was_missing    100000\n",
       " dtype: int64,\n",
       " (20000, 21),\n",
       " id                          20000\n",
       " d                           20000\n",
       " sales                       20000\n",
       " date                        20000\n",
       " wm_yr_wk                    20000\n",
       " weekday                     20000\n",
       " wday                        20000\n",
       " month                       20000\n",
       " year                        20000\n",
       " event_name_1                20000\n",
       " event_type_1                20000\n",
       " event_name_2                20000\n",
       " event_type_2                20000\n",
       " snap_CA                     20000\n",
       " snap_TX                     20000\n",
       " snap_WI                     20000\n",
       " sell_price                  20000\n",
       " event_name_1_was_missing    20000\n",
       " event_type_1_was_missing    20000\n",
       " event_name_2_was_missing    20000\n",
       " event_type_2_was_missing    20000\n",
       " dtype: int64,\n",
       " (1707440, 21),\n",
       " id                          1707440\n",
       " d                           1707440\n",
       " sales                       1707440\n",
       " date                        1707440\n",
       " wm_yr_wk                    1707440\n",
       " weekday                     1707440\n",
       " wday                        1707440\n",
       " month                       1707440\n",
       " year                        1707440\n",
       " event_name_1                1707440\n",
       " event_type_1                1707440\n",
       " event_name_2                1707440\n",
       " event_type_2                1707440\n",
       " snap_CA                     1707440\n",
       " snap_TX                     1707440\n",
       " snap_WI                     1707440\n",
       " sell_price                  1707440\n",
       " event_name_1_was_missing    1707440\n",
       " event_type_1_was_missing    1707440\n",
       " event_name_2_was_missing    1707440\n",
       " event_type_2_was_missing    1707440\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer_values = {'event_name_1' :'None', 'event_type_1' :'None', \n",
    "                  'event_name_2' :'None', 'event_type_2' :'None'                  \n",
    "                 }\n",
    "df_train.fillna(value = imputer_values, inplace = True)\n",
    "df_test.fillna(value = imputer_values, inplace = True)\n",
    "df_submission.fillna(value = imputer_values, inplace = True)\n",
    "\n",
    "# Checking to see if there are any missing values\n",
    "# The number of rows in each DF should be equal to the count\n",
    "df_train.shape, df_train.count(), df_test.shape, df_test.count(), df_submission.shape, df_submission.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'd', 'weekday', 'event_name_1', 'event_type_1', 'event_name_2',\n",
       "       'event_type_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of all non-numeric data\n",
    "df_train.select_dtypes(include = 'object').columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 17), (20000, 17), (1707440, 17))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we're going to use pandas date exploding features, so the given dates will wind up being redundant\n",
    "drop_fields = ['weekday', 'year', 'wday', 'month']\n",
    "df_train.drop(drop_fields, axis = 1, inplace = True)\n",
    "df_test.drop(drop_fields, axis = 1, inplace = True)\n",
    "df_submission.drop(drop_fields, axis = 1, inplace = True)\n",
    "df_train.shape, df_test.shape, df_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next cell will change the IDs into categorical values.\n",
    "# But the submission file needs them in the original format, so saving them to a series for use below\n",
    "df_sub_ids = df_submission['id'].copy()\n",
    "\n",
    "# We'll need the d column for the submission file format.\n",
    "# But we can drop it from the train/test dfs as we already have date information in the DF\n",
    "df_train.drop(['d'], axis = 1, inplace = True)\n",
    "df_test.drop(['d'], axis = 1, inplace = True)\n",
    "df_sub_d = df_submission.pop('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encode\n",
    "# For RAM considerations, we're not going to one hot encode anything.\n",
    "# These are functions from fast.ai that convert objects to categories and keeps those categories consistent across training and test\n",
    "train_cats(df_train)\n",
    "apply_cats(df_test, df_train)\n",
    "apply_cats(df_submission, df_train)\n",
    "df_train.shape, df_test.shape, df_submission.shape\n",
    "\n",
    "# Change categories to numbers\n",
    "cat_cols = df_train.select_dtypes(include = 'category').columns\n",
    "for i in cat_cols:\n",
    "    df_train['cat_'+i] = df_train[i].cat.codes\n",
    "    df_test['cat_'+i] = df_test[i].cat.codes\n",
    "    df_submission['cat_'+i] = df_submission[i].cat.codes\n",
    "\n",
    "df_train.drop(cat_cols, axis = 1, inplace = True)\n",
    "df_test.drop(cat_cols, axis = 1, inplace = True)\n",
    "df_submission.drop(cat_cols, axis = 1, inplace = True)\n",
    "\n",
    "# Should return an empty list\n",
    "df_train.select_dtypes(include = 'category').columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should return an empty list\n",
    "df_train.select_dtypes(include = 'object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sales', 'wm_yr_wk', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price',\n",
       "       'event_name_1_was_missing', 'event_type_1_was_missing',\n",
       "       'event_name_2_was_missing', 'event_type_2_was_missing', 'cat_id',\n",
       "       'cat_event_name_1', 'cat_event_type_1', 'cat_event_name_2',\n",
       "       'cat_event_type_2', 'Year', 'Month', 'Week', 'Day', 'Dayofweek',\n",
       "       'Dayofyear', 'Is_month_end', 'Is_month_start', 'Is_quarter_end',\n",
       "       'Is_quarter_start', 'Is_year_end', 'Is_year_start', 'Elapsed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explode out the date column into a ton of columns that a model can use\n",
    "date_cols = df_train.select_dtypes(include = 'datetime64').columns\n",
    "for i in date_cols:\n",
    "    add_datepart(df_train, i)\n",
    "    add_datepart(df_test, i)\n",
    "    add_datepart(df_submission, i)\n",
    "\n",
    "# Should see many more columns at the end of the list (year, month... is_year_end, etc) \n",
    "# Should also not see a \"date\" column\n",
    "df_train.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales                         int16\n",
       "wm_yr_wk                      int16\n",
       "snap_CA                        int8\n",
       "snap_TX                        int8\n",
       "snap_WI                        int8\n",
       "sell_price                  float16\n",
       "event_name_1_was_missing       bool\n",
       "event_type_1_was_missing       bool\n",
       "event_name_2_was_missing       bool\n",
       "event_type_2_was_missing       bool\n",
       "cat_id                        int16\n",
       "cat_event_name_1               int8\n",
       "cat_event_type_1               int8\n",
       "cat_event_name_2               int8\n",
       "cat_event_type_2               int8\n",
       "Year                          int64\n",
       "Month                         int64\n",
       "Week                          int64\n",
       "Day                           int64\n",
       "Dayofweek                     int64\n",
       "Dayofyear                     int64\n",
       "Is_month_end                   bool\n",
       "Is_month_start                 bool\n",
       "Is_quarter_end                 bool\n",
       "Is_quarter_start               bool\n",
       "Is_year_end                    bool\n",
       "Is_year_start                  bool\n",
       "Elapsed                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should only see number and boolean columns\n",
    "df_train.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  4.20 Mb (50.6% reduction)\n",
      "Mem. usage decreased to  0.82 Mb (51.1% reduction)\n",
      "Mem. usage decreased to 83.05 Mb (46.3% reduction)\n"
     ]
    }
   ],
   "source": [
    "reduce_mem_usage(df_train)\n",
    "reduce_mem_usage(df_test)\n",
    "reduce_mem_usage(df_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test we'll use below, the submission file sales column is all 0's so, we can just get rid of it.\n",
    "y_train = df_train.pop('sales')\n",
    "y_test = df_test.pop('sales')\n",
    "df_submission.drop(['sales'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.62 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Model\n",
    "\n",
    "m = RandomForestRegressor(n_jobs =-1) \n",
    "%time m.fit(df_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.272496518935363"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R squared scoring - \n",
    "m.score (df_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9467190954428273"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For making predictions that we'll submit put train and test together and fit the model again for better predictions\n",
    "train_test_concat = pd.concat([df_test, df_train])\n",
    "y_concat = pd.concat([y_test, y_train])\n",
    "m.fit(train_test_concat, y_concat)\n",
    "\n",
    "# new score\n",
    "m.score (train_test_concat, y_concat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wm_yr_wk                      int16\n",
       "snap_CA                        int8\n",
       "snap_TX                        int8\n",
       "snap_WI                        int8\n",
       "sell_price                  float16\n",
       "event_name_1_was_missing       bool\n",
       "event_type_1_was_missing       bool\n",
       "event_name_2_was_missing       bool\n",
       "event_type_2_was_missing       bool\n",
       "cat_id                        int16\n",
       "cat_event_name_1               int8\n",
       "cat_event_type_1               int8\n",
       "cat_event_name_2               int8\n",
       "cat_event_type_2               int8\n",
       "Year                          int16\n",
       "Month                          int8\n",
       "Week                           int8\n",
       "Day                            int8\n",
       "Dayofweek                      int8\n",
       "Dayofyear                     int16\n",
       "Is_month_end                   bool\n",
       "Is_month_start                 bool\n",
       "Is_quarter_end                 bool\n",
       "Is_quarter_start               bool\n",
       "Is_year_end                    bool\n",
       "Is_year_start                  bool\n",
       "Elapsed                       int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92, 0.09, 0.74, ..., 1.55, 0.7 , 1.72])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And finally, let's make some predictions that we'll submit\n",
    "predictions = m.predict(df_submission)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission file\n",
    "\n",
    "Submission file must be in format required by Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predictions made above and the original ids back onto the dataframe\n",
    "df_submission['sales'] = predictions\n",
    "df_submission['id'] = df_sub_ids\n",
    "df_submission['F'] = df_sub_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>d_1914</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>d_1914</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>d_1914</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>d_1914</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>d_1914</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id       F  preds\n",
       "0  HOBBIES_1_001_CA_1_validation  d_1914   0.92\n",
       "1  HOBBIES_1_002_CA_1_validation  d_1914   0.09\n",
       "2  HOBBIES_1_003_CA_1_validation  d_1914   0.74\n",
       "3  HOBBIES_1_004_CA_1_validation  d_1914   2.97\n",
       "4  HOBBIES_1_005_CA_1_validation  d_1914   2.85"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'id': df_sub_ids,'F': df_sub_d, 'preds': predictions}\n",
    "sub_file = pd.DataFrame(data=d)\n",
    "sub_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>F1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>F1</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>F1</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>F1</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>F1</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id   F  preds\n",
       "0  HOBBIES_1_001_CA_1_validation  F1   0.92\n",
       "1  HOBBIES_1_002_CA_1_validation  F1   0.09\n",
       "2  HOBBIES_1_003_CA_1_validation  F1   0.74\n",
       "3  HOBBIES_1_004_CA_1_validation  F1   2.97\n",
       "4  HOBBIES_1_005_CA_1_validation  F1   2.85"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As per the competition requirements, we have to change the \"d\" values to F values\n",
    "sub_file['F'] = sub_file['F'].str.replace('d_','')\n",
    "sub_file['F'] = pd.to_numeric(sub_file['F'], errors='coerce') \n",
    "sub_file['F'] = sub_file['F'] - 1913\n",
    "sub_file['F'] = 'F'+ sub_file['F'].astype(str)\n",
    "sub_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>F</th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>...</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_001_CA_2_evaluation</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_1_001_CA_2_validation</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_1_001_CA_3_evaluation</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "F                           id    F1   F10   F11   F12   F13   F14   F15  \\\n",
       "0  FOODS_1_001_CA_1_evaluation  1.28  1.32  1.32  1.18  1.25  1.26  1.32   \n",
       "1  FOODS_1_001_CA_1_validation  1.28  1.32  1.32  1.18  1.25  1.26  1.32   \n",
       "2  FOODS_1_001_CA_2_evaluation  1.28  1.32  1.32  1.18  1.25  1.26  1.32   \n",
       "3  FOODS_1_001_CA_2_validation  2.15  1.69  1.69  1.50  1.66  1.94  1.69   \n",
       "4  FOODS_1_001_CA_3_evaluation  1.28  1.32  1.32  1.18  1.25  1.26  1.32   \n",
       "\n",
       "F   F16   F17  ...   F26   F27   F28    F3    F4    F5    F6    F7    F8    F9  \n",
       "0  1.32  1.32  ...  1.18  1.25  1.02  1.28  1.28  1.19  1.26  1.26  1.32  1.32  \n",
       "1  1.32  1.32  ...  1.18  1.25  1.02  1.28  1.28  1.19  1.26  1.26  1.32  1.32  \n",
       "2  1.32  1.32  ...  1.18  1.25  1.02  1.28  1.28  1.19  1.26  1.26  1.32  1.32  \n",
       "3  1.69  1.69  ...  1.50  1.66  1.67  2.15  2.15  2.07  2.31  1.94  1.69  1.69  \n",
       "4  1.32  1.32  ...  1.18  1.25  1.02  1.28  1.28  1.19  1.26  1.26  1.32  1.32  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot and reset the index to flatten the file\n",
    "sub_file = sub_file.pivot(index='id', columns='F', values='preds')\n",
    "sub_file = sub_file.reset_index()\n",
    "sub_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally... we have our submisison file...\n",
    "csv_submit = sub_file.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
